{
 "metadata": {
  "colabVersion": "0.1",
  "name": "",
  "signature": "sha256:65ba73c5c7f376936c7f2461c266aead500d3fdb53a4ce93e625a6e318a3c68f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Redirection\n",
      "-----------\n",
      "\n",
      "### The `>` operator\n",
      "\n",
      "A very important command-line operator is the \u201credirection\u201d operator \u201c`>`\u201d.  With \u201c`>`\u201d you can send the result of your command-line processing to a file.  So if you\u2019re using curl to get your current location, using the ip-api.com service (see the previous section) and want to store the output into a file, you can create a new file with just these lines using redirection:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl 'http://www.telize.com/geoip' > location.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100   348  100   348    0     0   1880      0 --:--:-- --:--:-- --:--:--  1881\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl 'http://www.telize.com/geoip' -o location2.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "alldata.txt\r\n",
        "A quick tour of IPython Notebook.ipynb\r\n",
        "Assignment 1 Template (Using pipes, filters, and jq).ipynb\r\n",
        "dictionary.com\r\n",
        "Extract emails from webpage.ipynb\r\n",
        "Extract restaurant names using Pandas.ipynb\r\n",
        "facedetection.json\r\n",
        "faceplusplus.json\r\n",
        "images\r\n",
        "location.json\r\n",
        "Module 2a - Basic Unix Shell Commands.ipynb\r\n",
        "Module 2b - Fetching data using CURL.ipynb\r\n",
        "Module 2c - Pipes, filters, and more Unix Commands.ipynb\r\n",
        "Module 3a - Python Primer; Primitive Data Types.ipynb\r\n",
        "Module 3b - Python Primer; Lists, Sets, Tuples, Dictionaries.ipynb\r\n",
        "Module 3c - Python Primer; Control Flow Statements.ipynb\r\n",
        "Module 3d - Python Primer; Reading and Writing Files.ipynb\r\n",
        "Module 3e - Python Primer; Functions and Classes.ipynb\r\n",
        "Module 3f - Python Primer; Libraries and Matplotlib example.ipynb\r\n",
        "Module 3g - Python Primer; In-class exercise.ipynb\r\n",
        "Module 4a - Regular Expressions and grep.ipynb\r\n",
        "Module 4b - Regular Expressions using Python.ipynb\r\n",
        "Module 5a - Accessing Web APIs using Python.ipynb\r\n",
        "Module 5b - Accessing LinkedIn API.ipynb\r\n",
        "Module 5b - Accessing the Facebook API.ipynb\r\n",
        "Module 5c - XPath Tutorial.ipynb\r\n",
        "Module 5d - Crawling HTML pages.ipynb\r\n",
        "Module 5e - Crawling HTML; Buzzfeed in-class example.ipynb\r\n",
        "openweathermap.url\r\n",
        "pandas-cookbook-master\r\n",
        "phonetest.txt\r\n",
        "sample.txt\r\n",
        "temp.txt\r\n",
        "weather.json\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To see the content of the file, we can use the command `cat` (described below)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat location.json"
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": {
       "content": {
        "execution_count": 1,
        "payload": [],
        "status": "ok",
        "user_expressions": {},
        "user_variables": {}
       },
       "timestamp": 1409762051553,
       "user": {
        "color": "#1FA15D",
        "displayName": "Panos Ipeirotis",
        "isAnonymous": false,
        "isMe": true,
        "photoUrl": "//lh4.googleusercontent.com/-dIWj8iHQSKU/AAAAAAAAAAI/AAAAAAAA0Ro/MROYPWvY51A/s50-c-k-no/photo.jpg",
        "sessionId": "67a2c480bd9c6290",
        "userId": "103666871486129948108"
       },
       "user_tz": 240
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\"longitude\":-77.4875,\"latitude\":39.0437,\"asn\":\"AS14618\",\"offset\":\"-4\",\"ip\":\"54.174.159.22\",\"area_code\":\"0\",\"continent_code\":\"NA\",\"dma_code\":\"0\",\"city\":\"Ashburn\",\"timezone\":\"America\\/New_York\",\"region\":\"Virginia\",\"country_code\":\"US\",\"isp\":\"Amazon.com, Inc.\",\"postal_code\":\"20146\",\"country\":\"United States\",\"country_code3\":\"USA\",\"region_code\":\"VA\"}\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The `>>` operator\n",
      "\n",
      "If we want to append to a file (instead of creating a new file from scratch), then we can use the `>>` operator. The operator is useful in cases where we want to collect data over time (e.g., by setting up a script that runs every hour, and appends the data in the file, instead of overwriting what is there)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl 'http://www.telize.com/geoip' > alldata.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100   348  100   348    0     0   1830      0 --:--:-- --:--:-- --:--:--  1841\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl \"http://api.openweathermap.org/data/2.5/weather?lat=40.72&lon=-73.98&units=imperial&mode=json\" >> alldata.txt "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100   481    0   481    0     0   9469      0 --:--:-- --:--:-- --:--:--  9620\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat alldata.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\"longitude\":-77.4875,\"latitude\":39.0437,\"asn\":\"AS14618\",\"offset\":\"-4\",\"ip\":\"54.174.159.22\",\"area_code\":\"0\",\"continent_code\":\"NA\",\"dma_code\":\"0\",\"city\":\"Ashburn\",\"timezone\":\"America\\/New_York\",\"region\":\"Virginia\",\"country_code\":\"US\",\"isp\":\"Amazon.com, Inc.\",\"postal_code\":\"20146\",\"country\":\"United States\",\"country_code3\":\"USA\",\"region_code\":\"VA\"}\r\n",
        "{\"coord\":{\"lon\":-73.98,\"lat\":40.72},\"sys\":{\"message\":0.095,\"country\":\"US\",\"sunrise\":1421583365,\"sunset\":1421618210},\"weather\":[{\"id\":501,\"main\":\"Rain\",\"description\":\"moderate rain\",\"icon\":\"10d\"}],\"base\":\"cmc stations\",\"main\":{\"temp\":44.07,\"temp_min\":44.07,\"temp_max\":44.07,\"pressure\":1020.99,\"sea_level\":1024.93,\"grnd_level\":1020.99,\"humidity\":88},\"wind\":{\"speed\":8.12,\"deg\":170.002},\"clouds\":{\"all\":92},\"rain\":{\"3h\":10.5},\"dt\":1421607608,\"id\":5128581,\"name\":\"New York\",\"cod\":200}\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pipes\n",
      "-----\n",
      "\n",
      "Pipes provide a way of connecting the output of one unix program or utility to the input of another, through standard input and output. \n",
      "\n",
      "Unix pipes give you the power to compose various utilities into a data flow and use your creativity to solve problems. Utilities are connected together (\"piped\" together) via the pipe operator, |. \n",
      "\n",
      "We will give more examples that use piper later, after covering a few useful utilities first."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Filters\n",
      "-------\n",
      "\n",
      "###`cat`:\n",
      "\n",
      "Prints the contents of the specified files to standard output. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -s -L 'https://dl.dropboxusercontent.com/u/16006464/DwD_Winter2015/sample.txt' -o sample.txt #retrieve the file\n",
      "!cat sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we also want to number the lines, we use the `-n` option:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat -n sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise\n",
      "\n",
      "* Let's get now the \"Restaurant Inspection Results_\" results from the [NYC Open Data](https://nycopendata.socrata.com/) website.\n",
      "\n",
      "* Click on the top \"1100+ Data Sets available\" and then search for the term \"_Restaurant Inspection Results_\"\n",
      "\n",
      "* Go to the data set and get the link for downloading the ZIP file.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#your code here: download the file and store it under /home/ubuntu/data/restaurants.csv\n",
      "\n",
      "!curl \"https://data.cityofnewyork.us/api/views/xx67-kt59/rows.csv?accessType=DOWNLOAD\" -o /home/ubuntu/data/rests.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note 1: The -L flag tells curl to follow \"redirects\" and -s tells curl not to print any output or statistics but rather store the file in the file specified by the -o flag.)\n",
      "\n",
      "Note 2: This dataset is approximately 200Mb; a URL to download a zipped version (~9.5Mb) is at https://dl.dropboxusercontent.com/u/16006464/DwD_Winter2015/restaurant.zip\n",
      "\n",
      "Note 3: You need to unzip the restaurant.zip file to get the contents. (If needed, the `unzip` command can be installed using `sudo apt-get install unzip`.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl \"https://dl.dropboxusercontent.com/u/16006464/DwD_Winter2015/restaurant.zip\" -o /home/ubuntu/data/rests.zip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 9833k  100 9833k    0     0  16.6M      0 --:--:-- --:--:-- --:--:-- 16.6M\r\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/bin/sh: 1: cd: can't cd to data\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### `head/tail`:\n",
      "\n",
      "Output the first (last) lines of a file. Typically used like:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 5 sample.txt "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!tail -n 5 sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "140\t1346710000\t11122\thee haw\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The -n option specifies the number of lines to be output, the default value is 10. tail, when used with the -f option, will output the end of a file as it is written to. This is useful is a program is writing output or logging progress to a file, and you want to read it as it is happening."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###`less`:\n",
      "\n",
      "The command `cat` lets you see the contents of the file, but it is not convenient when the file is big. For that, it is better to use the command `less` which allows you to scroll and navigate through the contents of a file. When invoked like: `less [some big file]`. `less` enters an interactive mode. In this mode, several keys help you navigate the input file. Some key commands are:\n",
      "\n",
      "+ `(space)`: space navigates forward one screen.\n",
      "+ `(enter)`: enter navigates forward one line.\n",
      "+ `b`: navigates backwards one screen\n",
      "+ `y`: navigates backwards one line.\n",
      "+ `/[pattern]`: search forwards for the next occurrence of `[pattern]`\n",
      "+ `?[pattern]`: search backwards for the previous occurrence of `[pattern]`\n",
      "\n",
      "Where `[pattern]` can be a basic string or a regular expression. (We will cover regular expressions in the next session)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###`sort`\n",
      "\n",
      "An extremely efficient implementation of [external merge sort](http://dzmitryhuba.blogspot.com/2010/08/external-merge-sort.html). In a nutshell, this means the sort utility can order a dataset far larger than can fit in a system\u2019s main memory. While sorting extremely large files does drastically increase the runtime, smaller files are sorted quickly. Useful both as a component of larger shell scripts, and independently, as a tool to, say, quickly find the most active users, or to see the  most frequently loaded pages on a domain. \n",
      "\n",
      "Typically called like: `sort [options] [file]`. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Some useful options:\n",
      "\n",
      "+ `-r`: reverse order. Sort the input in descending order:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -r sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "123\t1346699925\t11122\tfoo bar\r\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ `-n`: numeric order. Sort the input in numerical order as opposed to the default lexicographical order:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -n sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "123\t1346699925\t11122\tfoo bar\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "234\t1346700000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ `-k n`: sort the input according to the values in the n-th column. Useful for columnar  data. See also the -t option to specify the text used to specify columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -k 2 -t, sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise\n",
      "\n",
      "Sort the NYC Restaurant dataset by restaurant name. You will see that this is a comma separated file therefore the character that separates columns is the `,` (comma) character. The restaurant name is the second column in the dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#your code here: Get the restaurant names (the \"DBA\" column) and store them in a separate file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###`uniq`\n",
      "\n",
      "Remove sequential duplicates: prints only those unique sequential lines from a file. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!uniq sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Used with the `-c` option, uniq will report the number of duplicates of each line in the sequence. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!uniq -c sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      1 123\t1346699925\t11122\tfoo bar\r\n",
        "      1 222\t1346699955\t11145\tbiz baz\r\n",
        "      1 140\t1346710000\t11122\thee haw\r\n",
        "      1 234\t1346700000\t11135\tbip bop\r\n",
        "      1 146\t1346699999\t11123\tfoo bar\r\n",
        "      2 99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###`wc`: \n",
      "Compute word, line, and byte counts for specified files or output of other scripts. Particularly useful when used in concert with other utilities such as grep, sort, and uniq. Example usage:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  7  35 201 sample.txt\r\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Indicating the number of lines, words, and bytes in the file respectively. There are some useful flags for wc that will help you answer specific questions quickly:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ `-l`: get the number of lines from the input. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc -l sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7 sample.txt\r\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ `-w`: get the number of words in the input. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc -w sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "35 sample.txt\r\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ `-m`: the number of characters in the input. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc -m sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "201 sample.txt\r\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ `-c`: the number of bytes in the input. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc -c sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, the number of bytes and characters are the same; all characters used are just one byte."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###`cut`:\n",
      "\n",
      "Used to select or \u201ccut\u201d certain fields (usually columns) from input. Cut is typically used with the `-f` option to specify a comma-separated list of columns to be emitted. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cut -f4,1 sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\tfoo bar\r\n",
        "222\tbiz baz\r\n",
        "140\thee haw\r\n",
        "234\tbip bop\r\n",
        "146\tfoo bar\r\n",
        "99\tbip bop\r\n",
        "99\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An important option with the cut utility is `-d`, which is used to specify the string used to separate the fields in the input. While the default value of tab is appropriate for our sample file, if spaces were used instead of tabs, we could change the above command to:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cut -f2,4 sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1346699925\tfoo bar\r\n",
        "1346699955\tbiz baz\r\n",
        "1346710000\thee haw\r\n",
        "1346700000\tbip bop\r\n",
        "1346699999\tfoo bar\r\n",
        "1346750000\tbip bop\r\n",
        "1346750000\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise\n",
      "\n",
      "* Get the restaurant names from the NYC Restaurant dataset\n",
      "* Remove any duplicate names\n",
      "* Sort the deduplicateds results\n",
      "* Report how many unique restaurants are in the dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###`grep`:\n",
      "A utility for pattern matching. grep is by far the most useful unix utility. While grep is conceptually very simple, an effective developer or data scientist will no doubt find themselves using grep dozens of times a day. grep is typically called like this: `grep [options] [pattern] [files]`. With no options specified, this simply looks for the specified pattern in the given files, printing to the console only those lines that match the given pattern. Example:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This in itself can be very useful, scraping large volumes of data to find what you\u2019re looking for. \n",
      "\n",
      "The power of grep really shows when different command options are specified. Below are just a sample of the more useful grep options:\n",
      "\n",
      "+ `-v`: Inverted matching. In this setting, grep will return all the input lines that do not match the specified pattern. Example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat sample.txt"
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": null
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!grep 'biz baz' sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "222\t1346699955\t11145\tbiz baz\r\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!grep 'foo bar' sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!grep 'foo bar' sample.txt | wc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      2      10      58\r\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!grep 'foo bar' sample.txt | wc -l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\r\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ `-R`: Recursive matching. Here grep descends sub folders, applying the pattern on all files encountered. Very useful if you\u2019re looking to see if any logs have lines that you\u2019re interested in, or to find the source code file containing the function you\u2019re interested in. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd /home/ubuntu/data/; grep -R 'MORIMOTO' ."
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": null
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,07/02/2014,Violations were cited in the following area(s).,04C,Food worker does not use proper utensil to eliminate bare hand contact with food that will not receive adequate additional heat treatment.,Critical,11,A,07/02/2014,01/14/2015,Cycle Inspection / Initial Inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,07/02/2014,Violations were cited in the following area(s).,10B,Plumbing not properly installed or maintained; anti-siphonage or backflow prevention device not provided where required; equipment or floor not properly drained; sewage disposal system in disrepair or not functioning properly.,Not Critical,11,A,07/02/2014,01/14/2015,Cycle Inspection / Initial Inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,07/02/2014,Violations were cited in the following area(s).,10J,''''Wash hands\u001a sign not posted at hand wash facility.,Not Critical,11,A,07/02/2014,01/14/2015,Cycle Inspection / Initial Inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,01/16/2014,Violations were cited in the following area(s).,06C,\"Food not protected from potential source of contamination during storage, preparation, transportation, display or service.\",Critical,5,A,01/16/2014,01/14/2015,Cycle Inspection / Re-inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,10/08/2013,Violations were cited in the following area(s).,02B,Hot food item not held at or above 140\u00ba F.,Critical,34,,,01/14/2015,Cycle Inspection / Initial Inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,10/08/2013,Violations were cited in the following area(s).,02G,Cold food item held above 41\u00ba F (smoked fish and reduced oxygen packaged foods above 38 \u00baF) except during necessary preparation.,Critical,34,,,01/14/2015,Cycle Inspection / Initial Inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,10/08/2013,Violations were cited in the following area(s).,06A,Personal cleanliness inadequate. Outer garment soiled with possible contaminant.  Effective hair restraint not worn in an area where food is prepared.,Critical,34,,,01/14/2015,Cycle Inspection / Initial Inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,10/08/2013,Violations were cited in the following area(s).,06E,\"Sanitized equipment or utensil, including in-use food dispensing utensil, improperly used or stored.\",Critical,34,,,01/14/2015,Cycle Inspection / Initial Inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,10/08/2013,Violations were cited in the following area(s).,10F,\"Non-food contact surface improperly constructed. Unacceptable material used. Non-food contact surface or equipment improperly maintained and/or not properly sealed, raised, spaced or movable to allow accessibility for cleaning on all sides, above and underneath the unit.\",Not Critical,34,,,01/14/2015,Cycle Inspection / Initial Inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,10/08/2013,Violations were cited in the following area(s).,10J,''''Wash hands\u001a sign not posted at hand wash facility.,Not Critical,34,,,01/14/2015,Cycle Inspection / Initial Inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,02/25/2013,Violations were cited in the following area(s).,04C,Food worker does not use proper utensil to eliminate bare hand contact with food that will not receive adequate additional heat treatment.,Critical,12,A,02/25/2013,01/14/2015,Cycle Inspection / Re-inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,02/25/2013,Violations were cited in the following area(s).,06A,Personal cleanliness inadequate. Outer garment soiled with possible contaminant.  Effective hair restraint not worn in an area where food is prepared.,Critical,12,A,02/25/2013,01/14/2015,Cycle Inspection / Re-inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,01/24/2013,Violations were cited in the following area(s).,04C,Food worker does not use proper utensil to eliminate bare hand contact with food that will not receive adequate additional heat treatment.,Critical,17,,,01/14/2015,Cycle Inspection / Initial Inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,01/24/2013,Violations were cited in the following area(s).,06I,Food not labeled in accordance with HACCP plan.,Critical,17,,,01/14/2015,Cycle Inspection / Initial Inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,12/13/2011,Violations were cited in the following area(s).,02G,Cold food item held above 41\u00ba F (smoked fish and reduced oxygen packaged foods above 38 \u00baF) except during necessary preparation.,Critical,9,A,12/13/2011,01/14/2015,Cycle Inspection / Initial Inspection\r\n",
        "./restaurant.csv:41159798,MORIMOTO NY,MANHATTAN,88        ,10 AVENUE                                         ,10011,2129894639,Japanese,12/13/2011,Violations were cited in the following area(s).,10B,Plumbing not properly installed or maintained; anti-siphonage or backflow prevention device not provided where required; equipment or floor not properly drained; sewage disposal system in disrepair or not functioning properly.,Not Critical,9,A,12/13/2011,01/14/2015,Cycle Inspection / Initial Inspection\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More options:\n",
      "\n",
      "* -c\tPrint only a count of matched lines.\n",
      "* -i \tIgnore lowercase and uppercase distinctions\n",
      "* -n\tPrint matching line with its line number\n",
      "* -v  \tNegate matches; print lines that do not match the regex\n",
      "* -r\tRecursively Search subdirectories listed\n",
      "* -l \tList only filenames\n",
      "* -o\tprints only the matching part of the line\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will get back to grep next session, once we learn regular expressions. You will see that grep can be extremely useful for searching through data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### `jq`\n",
      "\n",
      "The [jq](http://stedolan.github.io/jq/) is not one of the \"standard\" UNIX tools but will be useful for us, to be able to parse the JSON responses of the Web API calls.\n",
      "\n",
      "Since it is not installed by default, we need to first install it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sudo apt-get install jq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `jq` command has the format\n",
      "\n",
      "`jq [filters] filename`\n",
      "\n",
      "\n",
      "\n",
      "The absolute simplest (and least interesting) filter is `.` \n",
      "\n",
      "This is a filter that takes its input and produces it unchanged as output.\n",
      "\n",
      "Since jq by default \"pretty-prints\" all output, this trivial program can be a useful way of formatting JSON output from, say, curl.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!jq . location.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[37m{\r\n",
        "  \u001b[0m\u001b[34;1m\"region_code\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"VA\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"dma_code\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"0\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"continent_code\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"NA\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"area_code\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"0\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"ip\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"54.174.159.22\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"offset\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"-4\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"asn\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"AS14618\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"latitude\"\u001b[0m\u001b[37m: \u001b[0m\u001b[0m39.0437\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"longitude\"\u001b[0m\u001b[37m: \u001b[0m\u001b[0m-77.4875\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"city\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"Ashburn\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"timezone\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"America/New_York\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"region\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"Virginia\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"country_code\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"US\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"isp\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"Amazon.com, Inc.\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"postal_code\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"20146\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"country\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"United States\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"country_code3\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"USA\"\u001b[0m\u001b[37m\r\n",
        "\u001b[37m}\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Having learned pipes, we can now avoid storing the output of curl into a file, and instead pass it directly through `jq`: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -s 'http://www.telize.com/geoip' | jq . "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[37m{\r\n",
        "  \u001b[0m\u001b[34;1m\"region_code\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"VA\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"dma_code\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"0\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"continent_code\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"NA\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"area_code\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"0\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"ip\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"54.174.159.22\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"offset\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"-4\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"asn\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"AS14618\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"latitude\"\u001b[0m\u001b[37m: \u001b[0m\u001b[0m39.0437\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"longitude\"\u001b[0m\u001b[37m: \u001b[0m\u001b[0m-77.4875\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"city\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"Ashburn\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"timezone\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"America/New_York\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"region\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"Virginia\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"country_code\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"US\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"isp\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"Amazon.com, Inc.\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"postal_code\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"20146\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"country\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"United States\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"country_code3\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"USA\"\u001b[0m\u001b[37m\r\n",
        "\u001b[37m}\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(The -s option for curl stands for \"silent\" and prevents the status messages from appearing in the output).\n",
      "\n",
      "The simplest useful filter is `.foo`. When given a JSON object as input, it produces the value at the attribute `foo`, or null if there\u2019s none present.\n",
      "\n",
      "Now, let's try to use such a filter for selecting the \"city\" attribute listed in the JSON output: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -s 'http://www.telize.com/geoip' | jq '.city'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[32m\"Ashburn\"\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And we can also combine multiple attributes, using the addition operator `+`: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -s 'http://www.telize.com/geoip' | jq '.city + \", \" + .region'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[32m\"Ashburn, Virginia\"\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's try something more complicated: We will use the jq command to read the location from the output of the ip-api.com API, and then create the URL for calling the OpenWeathermap API (see the previous session for details):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -s 'http://www.telize.com/geoip' | \\\n",
      "jq '\"http://api.openweathermap.org/data/2.5/weather?q=\" + .city + \", \" + .region + \"&mode=json&units=imperial\"'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[32m\"http://api.openweathermap.org/data/2.5/weather?q=Ashburn, Virginia&mode=json&units=imperial\"\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, let's also use the `xargs` command (covered below), in order to call this URL directly, and get the weather in our current location:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -s 'http://ip-api.com/json' | \\\n",
      "jq '\"http://api.openweathermap.org/data/2.5/weather?q=\" + .city + \", \" + .region + \"&mode=json&units=imperial\"' | \\\n",
      "xargs curl | jq '.main.temp'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100   464    0   464    0     0  19441      0 --:--:-- --:--:-- --:--:-- 20173\r\n",
        "\u001b[0m30.88\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curl \"http://www.nyu.edu\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -s 'http://ip-api.com/json' > location.json\n",
      "!jq '\"http://api.openweathermap.org/data/2.5/weather?q=\" + .city + \", \" + .region + \"&mode=json&units=imperial\"' location.json > openweathermap.url\n",
      "!cat openweathermap.url | xargs -L 1 curl -s > weather.json\n",
      "!jq '.main.temp' weather.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[0m34.48\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Look at the power of pipes and filters: In three lines and in less than 200 characters, we created a service that reads out current location, using the API at ip-api.com, parses the output, creates a new API call for OpenWeatherMap, and then gets the data from that service, to give us back the temperature in our current location!\n",
      "\n",
      "The full manual of `jq` is available at http://stedolan.github.io/jq/manual/ and you can use the live demo at https://jqplay.org/\n",
      "\n",
      "There are numerous options in the manual. For now, you can restrict yourself to the basic operations that we covered."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise\n",
      "\n",
      "* Instead of reading the city and region, read instead the log/lat coordinates, and modify the API call to OpenWeatherMap to use long/lat instead. (See http://openweathermap.org/current for the details API calls.)\n",
      "\n",
      "* Print the description of the weather, instead of the temperature."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More examples of using pipes\n",
      "----------------------------\n",
      "\n",
      "We discussed earlier in the session the usage of the `|` operator to connect (aka \"pipe\") the output of one utility and direct it as input in another. Now that we have learned a few tools, lets use these in some examples. For instance, if you want to know how many records in the sample data file do not contain \"foo bar\", you can compose a data flow like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat sample.txt | grep -v 'foo bar' | wc -l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using `wc` at the end of a pipe to count the number of matching output records is a common pattern. Recalling that `uniq` removes any sequential duplicates, we can count the number of unique users making purchases in our file by composing a data flow like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat sample.txt | cut -f3 | sort | uniq  | wc -l"
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": null
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or, if you want count how many transactions each user has appeared in:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat sample.txt | cut -f3 | sort | uniq -c"
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": null
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To now order the users by number of transactions made, you can try something like:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat sample.txt | cut -f3 | sort | uniq -c | sort -nr"
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": null
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice here, that the `-r` and `-n` flags for the sort command are combined. This is common shorthand and is acceptable for any unix utility."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More Useful Command Line Utilities:\n",
      "-----------------------------------\n",
      "\n",
      "+ [`xargs`](http://linux.die.net/man/1/xargs): used for building and executing terminal commands. Often used to read input from a pipe, and perform the same command on each line read from the pipe. For instance, if we want to look up all of the .txt files in a directory and concatenate them, we can use xargs:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls . | grep '.txt' | xargs cat"
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": null
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ [`find`](http://linux.die.net/man/1/find): search directories for matching files. Useful when you know the name of a file (or part of the name), but do not know the file\u2019s location in a directory. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!find . -name 'sample.txt'"
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": null
     },
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Running Jobs in the Background"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sometimes, we would like to start a task, and let it run in the background. To do so, we simply add the character `&` at the end of the command. For example, if we want to run a long running task using grep, and store the results in a file, we can type:\n",
      "\n",
      "`cd /home/ubuntu/data/`\n",
      "`grep -R 'MORIMOTO' . > morimoto.txt &`\n",
      "\n",
      "#### Standard output, Standard Error\n",
      "\n",
      "When we run tasks in the background, it is often useful to separate the storing of the program output from the program errors. This is done by using the `2>` redirect operator, which redirects the error messages to the file of our choice.\n",
      "\n",
      "`grep -R 'MORIMOTO' . > morimoto.txt 2> morimoto-errors.txt &`\n",
      "\n",
      "If we prefer to store both standard output and standard error in the same file, we use the `2>&1` command:\n",
      "\n",
      "`grep -R 'MORIMOTO' . > morimoto.txt 2>&1 &`\n",
      "\n",
      "#### Nohup\n",
      "\n",
      "When we use the `&` operator, the task runs in the background, but stops running the moment we logout from our ssh session. To allow the task to continue running, even after we log out, we can use the `nohup` command, as follows:\n",
      "\n",
      "`nohup grep -R 'MORIMOTO' . > morimoto.txt 2> morimoto-errors.txt &`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise\n",
      "\n",
      "Start downloading a big data set (e.g., the restaurant data set) using CURL. Use the -s option to put it in silent mode, and use the nohup command and the & operator to let the process run in the background."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Cron: Scheduling Tasks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "      \n",
      "Cron is used to execute desired tasks (in the background) at designated times. \n",
      "\n",
      "A crontab is a simple text file with a list of commands meant to be run at specified times and these jobs will run regardless of whether the user is actually logged into the system. \n",
      "\n",
      "To use cron for tasks meant to run only for your user profile, add entries to your own user's crontab file. Start the crontab editor from a terminal window:\n",
      "\n",
      "`sudo crontab -e`\n",
      "\n",
      "### The structure of the crontab file\n",
      "\n",
      "This is how a cron job is laid out:\n",
      "\n",
      "minute (0-59), hour (0-23, 0 = midnight), day (1-31), month (1-12), weekday (0-6, 0 = Sunday), command\n",
      "\n",
      "and each line of the crontab file has the following format:\n",
      "\n",
      "`minute hour day_of_month month day_of_week   command`\n",
      "\n",
      "Each of the parts is separated by a space, with the final part (the command) having one or more spaces in it. \n",
      "For example, you can run a backup of all your user accounts at 5 a.m every week with:\n",
      "\n",
      "`0 5 * * 1 tar -zcf /var/backups/home.tgz /home/`\n",
      "\n",
      "#### More examples\n",
      "\n",
      "`01 04 1 1 1 /usr/bin/somedirectory/somecommand`\n",
      "The above example will run /usr/bin/somedirectory/somecommand at 4:01am on January 1st plus every Monday in January. An asterisk (\\*) can be used so that every instance (every hour, every weekday, every month, etc.) of a time period is used. Code:\n",
      "\n",
      "\n",
      "`01 04 * * * /usr/bin/somedirectory/somecommand`\n",
      "The above example will run /usr/bin/somedirectory/somecommand at 4:01am on every day of every month.\n",
      "\n",
      "Comma-separated values can be used to run more than one instance of a particular command within a time period. Dash-separated values can be used to run a command continuously. For example:\n",
      "\n",
      "`01,31 04,05 1-15 1,6 * /usr/bin/somedirectory/somecommand`\n",
      "\n",
      "The above example will run /usr/bin/somedirectory/somecommand at 01 and 31 past the hours of 4:00am and 5:00am on the 1st through the 15th of every January and June.\n",
      "\n",
      "The `/usr/bin/somedirectory/somecommand` text in the above examples indicates the task which will be run at the specified times. It is recommended that you use the full path to the desired commands as shown in the above examples. Enter which somecommand in the terminal to find the full path to somecommand. The crontab will begin running as soon as it is properly edited and saved.\n",
      "\n",
      "You may want to run a script some number of times per time unit. For example if you want to run it every 10 minutes use the following crontab entry (runs on minutes divisible by 10: 0, 10, 20, 30, etc.)\n",
      "\n",
      "`*/10 * * * * /usr/bin/somedirectory/somecommand`\n",
      "\n",
      "which is also equivalent to the more cumbersome\n",
      "\n",
      "`0,10,20,30,40,50 * * * * /usr/bin/somedirectory/somecommand`\n",
      "\n",
      "\n",
      "(See https://help.ubuntu.com/community/CronHowto for more details)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise\n",
      "\n",
      "* Use a cron job to keep track of the temperature in New York, running every minute. Use the OpenWeatherMap service and jq to get the temperature. Use the redirect operator to store the temperature in a text file called /home/ubuntu/data/nyc-temperatures.txt, appending a new line for every measurement."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}